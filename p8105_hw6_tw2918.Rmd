---
title: "p8105_hw6_tw2918"
output: github_document
date: "2023-11-20"
---

```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(modelr)
set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Probelm 1

**Import and Clean Dataset**

* update the victim's first and last name to proper case
* replace `unknown` to missing value `NA`
* update `victim_age` to numeric variable
* create new variable `city_state` and `case_resovled`, ane make `case_resovled` numeric
* filter out four `city_state` values
* filter and only keep observations if `victim_race` is white or black. 

```{r}
homicide_df = read_csv("./data/homicide_data.csv", show_col_types = FALSE) |>
  janitor::clean_names()|>
  mutate (
    victim_last = str_to_title(victim_last),
    victim_first = str_to_title(victim_first),
    across(c(uid, victim_last, victim_first, victim_race, victim_age, victim_sex, city, state, disposition), ~na_if(., "Unknown")),
    victim_age = as.numeric(victim_age),
    city_state = paste(city, state, sep = ", "),
    case_resolved = ifelse(grepl("Closed", disposition, ignore.case = TRUE), "1", "0"),
    case_resolved = as.numeric(case_resolved)
    )|>
  filter(
    !city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO" ),
    victim_race == "White" | victim_race == "Black"
    )

print(homicide_df)
```

**Logistic regression on city of Balitmore, MD**

For the city of `Baltimore, MD`, use the `glm` function to fit a logistic regression with `resolved` vs `unresolved` as the outcome and victim age, sex and race as predictors. Save the output of `glm` as an `R object`; 

```{r}
fit_logistic = homicide_df |>
  filter(city_state == "Baltimore, MD")|>
  glm(case_resolved ~ victim_age + victim_sex + victim_race,data = _, family = binomial())

print(fit_logistic)
```

apply the `broom::tidy` to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

```{r}
fit_logistic|>
  broom::tidy()|>
  filter(term == "victim_sexMale")|>
  mutate(OR = exp(estimate),
         ci_lower = exp(estimate - (1.96 * std.error)),
         ci_upper = exp(estimate + (1.96 * std.error))
      )|>
  select(term, OR, ci_lower, ci_upper)|>
  knitr::kable(digits = 3)
```

**Logistic regression on each of the city**

run `glm` for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of `purrr::map`, `list columns`, and `unnest` as necessary to create a dataframe with estimated ORs and CIs for each city.

```{r}
fit_logistic_allcity = homicide_df |>
    nest(df = -city_state)|>
  mutate(
    glm_model = purrr::map(df, \(df) 
                     glm(case_resolved ~ victim_age + victim_sex + victim_race,data =df, family = binomial())),
    glm_result = map (glm_model, broom::tidy)
  )|>
  select(city_state, glm_result)|>
  unnest(glm_result)|>
  filter(term == "victim_sexMale")|>
  mutate(OR = exp(estimate),
         ci_lower = exp(estimate - (1.96 * std.error)),
         ci_upper = exp(estimate + (1.96 * std.error))
      )|>
  select(city_state, OR, ci_lower, ci_upper)

print(fit_logistic_allcity)
```

**Plot for OR and CI**

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r}
fit_logistic_allcity |>
  mutate(city_state = reorder(city_state, OR))|>
  ggplot(aes(x=city_state, y =OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper))+
  labs(
    title = "Estimated OR and Confidance Interval of Solving Homicides Comparing Male to Female Victims in Each City ",
    x = "Cities and States",
    y = "Estimated OR",
  ) +
  theme(axis.text.x =element_text(angle = 90, hjust = 1))
```

*Comment on the plot*

* The plot shows the estimated OR and confidence intervals for solving homicides, comparing male to female victims in each cities and we are 95% confidence that the true OR lies between the confidence intervals. If the confidence interval cross y=1, then there's no significant evidence of a difference in the odds of solving homicides between male and female victims.That is the case 15 out of 47 cities. 
* We also see that most of the estimated OR is less than 1, which suggests that in most states male victims' homicides are less likely to be solved compared to female victims' homicides in that city. That's the case for all evidence of a difference in the odds of solving homicides between male and female victims. For the 3 cities with estimated OR above 1, they all have CI including the value of 1 that suggested no true difference. 
* Some cities also have wide confidence intervals, which is the cities with CI cross the value of 1, which could indicate a small sample size or high variability within the data for those cities, which may be the causes for insignificant results. 

## Problem 2

**Import and Clean Dataset**

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

** Linear Regression and bootstrap**

Fit simple linear regression with tmax as the response with tmin and prcp as the predictors. Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of `r_squared` and `log(β0∗β1)`

```{r}
# set function draw a size from the dataframe of the exact size of the dataframe
boot_sample = function (df) {

  sample_frac(df, replace = TRUE)
  
}

# run bootstrap
boot_result = 
  tibble(strap_number = 1:5000) |>
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(weather_df)),
    models = map(strap_sample, \(df) lm (tmax ~ tmin + prcp, data = df)),
    r_squared = map(models, broom::glance),
    results = map(models, broom::tidy)
  )|>
  select(strap_number, results, r_squared) |>
  unnest(results, r_squared)|>
  select(strap_number, term, estimate, r.squared)|>
  pivot_wider(
    names_from = "term",
    values_from = "estimate" 
  )|>
  janitor:: clean_names()|>
  # log(b1*b2)
  mutate(
    log_beta= log(tmin*prcp)
  )|>
  select(strap_number, r_squared, log_beta)

print(boot_result)
```

* There are `r sum(is.na(boot_result$log_beta))` `NA` value for the log_beta, because some of the `beta1*beta2` value appear to be less than 0. 

Plot the distribution of your estimates, and describe these in words. 

```{r}
#R squared plot
boot_result|>
  ggplot(aes(x=r_squared)) +
  geom_density()+
  labs(title = "Density Plot of R_Squared", 
       x = "R_Squared", 
       y = "Density" 
       )

# log_beta plot
boot_result|>
  filter(!is.na(log_beta)) |>
  ggplot(aes(x=log_beta)) +
  geom_density()+
  labs(title = "Density Plot of Log_Beta", 
       x = "Log_Beta", 
       y = "Density" 
       )

```

*Comment on the Plot*

* The density plot for `r_squared` if approximately symmetric around the peak, but there appears to be a slight left skewness, indicating that there are a number of `r_squared` values lower than the mode.The tails of the distribution taper off, with fewer observations having very low or very high `r_squared` values.The peak of the density appears to occur somewhere between `-0.91` and `-0.92` on the x-axis, suggesting that this is the most common range of values for `r_squared`. 
* The density plot for `log(beta1*beta2)` appears to be left skewed with a tail on the left, suggesting that the mean and median are typically less than the mode. The peak of the density appears to occur somewhere between `-7` and `-6` on the x-axis, suggesting that this is the most common range of values for `log_beta`. 

Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for the two estimate.

```{r}
boot_result |>
  filter(!is.na(log_beta)) |>
  pivot_longer(
    r_squared:log_beta,
    names_to = "estimate",
    values_to = "value"
  )|>
  group_by(estimate)|>
  summarize(
    ci_lower = quantile(value, 0.025),
    ci_upper = quantile(value, 0.075)
  )|>
  knitr::kable(digits = 3)
```

## Problem 3

**Import and Clean Data**
* import dataset and clean name
* udpated the four variables `babysex` `frace` `malform` and `mrace` from numeric to character
* found only 1 missing value. Where in variable `menarche`, mother’s age at menarche (years), the age could not be 0, I have updated the value from 0 to NA.
```{r}
bwt_df = read_csv("./data/birthweight.csv", show_col_types = FALSE) |>
  janitor::clean_names()|>
  mutate(
    babysex = ifelse(babysex == 1, "Male", "Female"),
    frace = case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown",
      TRUE ~ as.character(frace)  
    ),
    malform = ifelse(malform == 0, "Absent", "Present"),
    mrace = case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other",
      TRUE ~ as.character(frace)  
    ),
    across(c(babysex, frace, malform, mrace), ~na_if(., "Unknown")),
    menarche = replace(menarche, menarche == 0, NA)
    )

colSums(is.na(bwt_df))
```

**Regression Model for Birthweight**

Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underlie birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.


```{r}
bwt_lm = 
  bwt_df |>
  lm(bwt ~ babysex + blength + gaweeks + momage + ppwt + smoken + wtgain, data = _ )

bwt_lm|>
  broom::tidy()|>
  knitr::kable()

bwt_lm|>
  broom::glance() |>
  knitr::kable()

```

*Model Building Process*

* **Proposed Model:Birthweight = babysex + blength + gaweeks + momage + ppwt + smoken + wtgain**
* I proposed model based on hypothesis that baby's sex, length, gestational age in weeks, mother’s age at delivery (years), mother’s weight at delivery (pounds), average number of cigarettes smoked per day during pregnancy, and mother’s weight gain during pregnancy (pounds) will impacted baby's birthweight. And from the coefficient and p.value produced we can tell that all of the predictors are significantly associated with birthweight because the p.value for each estimate coefficient is less than 0.05. R-squared produced tells us that these predictors combined explained 59.96% of the variability of birthweight. 

**Residual Plot**
Show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.

```{r}
bwt_df |> 
  modelr::add_residuals(bwt_lm) |> 
  modelr::add_predictions(bwt_lm)|>
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.2) +
  labs(
    x = "Fitted Values", 
    y = "Residuals", 
    title = "Plot of Residuals against Fitted Values") 
```

**Compare the Model and Cross Validation**

Compare your model to two others:

* One using length at birth and gestational age as predictors (main effects only)
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

Compare fitted value against residual

```{r}
proposed_model  = lm(bwt ~ babysex + blength + gaweeks + momage + ppwt + smoken + wtgain, data = bwt_df)
main_model= lm(bwt ~ blength + gaweeks, data = bwt_df)
interaction_model  = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = bwt_df)

bwt_df |> 
  gather_predictions (proposed_model, main_model, interaction_model) |> 
  gather_residuals(proposed_model, main_model, interaction_model) |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .5) +
  facet_grid(~model)
```


Make this comparison in terms of the cross-validated prediction error; use `crossv_mc` and functions in `purrr` as appropriate.
```{r}
cv_df = 
  crossv_mc(bwt_df, 100) 

cv_df = 
  cv_df |>
  mutate(
    proposed_model  = map(train, \(df) lm(bwt ~ babysex + blength + gaweeks + momage + ppwt + smoken + wtgain, data = df)),
    main_model  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interaction_model  = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = df))
    ) |>
  mutate(
    rmse_proposed = map2_dbl(proposed_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main = map2_dbl(main_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interaction = map2_dbl(interaction_model, test, \(mod, df) rmse(model = mod, data = df))
  )

cv_df |>
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```








